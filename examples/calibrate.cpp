/*
 * FAST-Calib Core Calibration Tool
 *
 * Camera-LiDAR extrinsic calibration from configuration file.
 * Supports both single-scene and multi-scene calibration.
 *
 * Usage: calibrate <config.yaml>
 *
 * Original project: https://github.com/hku-mars/FAST-Calib
 */

#include <pcl/io/pcd_io.h>

#include <Eigen/Geometry>
#include <fast_calib_core/calibration.hpp>
#include <fast_calib_core/config_parser.hpp>
#include <fast_calib_core/lidar_detector.hpp>
#include <fast_calib_core/qr_detector.hpp>
#include <fast_calib_core/types.hpp>
#include <filesystem>
#include <fstream>
#include <iomanip>
#include <iostream>

using namespace fast_calib;

// ============================================================================
// Helper Functions
// ============================================================================

/**
 * @brief Load point cloud from PCD file
 */
bool loadPointCloud(const std::string& pcd_file, LiDARType lidar_type,
                    PointCloudRingPtr& cloud) {
  cloud->clear();

  if (lidar_type == LiDARType::Solid) {
    // Solid-state LiDAR: load XYZ format and convert to XYZRing
    PointCloudXYZPtr xyz_cloud(new PointCloudXYZ);
    if (pcl::io::loadPCDFile<pcl::PointXYZ>(pcd_file, *xyz_cloud) == -1) {
      std::cerr << "Failed to load point cloud: " << pcd_file << std::endl;
      return false;
    }

    cloud->reserve(xyz_cloud->size());
    for (const auto& pt : xyz_cloud->points) {
      PointXYZRing pt_ring;
      pt_ring.x = pt.x;
      pt_ring.y = pt.y;
      pt_ring.z = pt.z;
      pt_ring.ring = 0;
      cloud->push_back(pt_ring);
    }
  } else {
    // Mechanical LiDAR: load XYZRing format directly
    if (pcl::io::loadPCDFile<PointXYZRing>(pcd_file, *cloud) == -1) {
      std::cerr << "Failed to load point cloud: " << pcd_file << std::endl;
      return false;
    }
  }

  return true;
}

/**
 * @brief Apply point cloud filter
 */
void filterPointCloud(const PointCloudRingPtr& input, PointCloudRingPtr& output,
                      const FilterConfig& filter) {
  output->clear();
  if (!filter.enabled) {
    *output = *input;
    return;
  }

  output->reserve(input->size());
  for (const auto& pt : input->points) {
    if (pt.x >= filter.min[0] && pt.x <= filter.max[0] &&
        pt.y >= filter.min[1] && pt.y <= filter.max[1] &&
        pt.z >= filter.min[2] && pt.z <= filter.max[2]) {
      output->push_back(pt);
    }
  }
}

/**
 * @brief Create output directory if not exists
 */
bool ensureOutputDir(const std::string& path) {
  try {
    std::filesystem::create_directories(path);
    return true;
  } catch (const std::exception& e) {
    std::cerr << "Failed to create output directory: " << e.what() << std::endl;
    return false;
  }
}

/**
 * @brief Save calibration result to file
 */
void saveResult(const std::string& output_path, const CalibConfig& config,
                const CalibrationResult& result) {
  std::string result_file = output_path + "/" +
                            (config.isMultiScene() ? "multi_calib_result.txt"
                                                   : "single_calib_result.txt");

  std::ofstream file(result_file);
  if (!file.is_open()) {
    std::cerr << "Failed to open output file: " << result_file << std::endl;
    return;
  }

  file << "# FAST-Calib result\n";
  file << "# Generated by fast_calib_core v" << getVersionString() << "\n";
  file << "# Mode: " << (config.isMultiScene() ? "multi-scene" : "single-scene")
       << " (" << config.scenes.size() << " scene(s))\n\n";

  file << "cam_model: Pinhole\n";
  file << "cam_fx: " << config.camera.fx << "\n";
  file << "cam_fy: " << config.camera.fy << "\n";
  file << "cam_cx: " << config.camera.cx << "\n";
  file << "cam_cy: " << config.camera.cy << "\n";
  file << "cam_d0: " << config.camera.k1 << "\n";
  file << "cam_d1: " << config.camera.k2 << "\n";
  file << "cam_d2: " << config.camera.p1 << "\n";
  file << "cam_d3: " << config.camera.p2 << "\n";

  const auto& T = result.transformation;
  file << "\nRcl: [" << std::fixed << std::setprecision(9);
  file << std::setw(12) << T(0, 0) << ", " << std::setw(12) << T(0, 1) << ", "
       << std::setw(12) << T(0, 2) << ",\n";
  file << "      " << std::setw(12) << T(1, 0) << ", " << std::setw(12)
       << T(1, 1) << ", " << std::setw(12) << T(1, 2) << ",\n";
  file << "      " << std::setw(12) << T(2, 0) << ", " << std::setw(12)
       << T(2, 1) << ", " << std::setw(12) << T(2, 2) << "]\n";

  file << "Pcl: [" << std::setw(12) << T(0, 3) << ", " << std::setw(12)
       << T(1, 3) << ", " << std::setw(12) << T(2, 3) << "]\n";

  file << "\nRMSE: " << result.rmse << " m\n";
  file.close();

  std::cout << "Result saved to: " << result_file << std::endl;

  // Also save transformation matrix
  std::string matrix_file = output_path + "/transformation.txt";
  std::ofstream mfile(matrix_file);
  if (mfile.is_open()) {
    mfile << std::fixed << std::setprecision(9);
    for (int i = 0; i < 4; ++i) {
      for (int j = 0; j < 4; ++j) {
        mfile << T(i, j);
        if (j < 3) mfile << " ";
      }
      mfile << "\n";
    }
    mfile.close();
  }

  // Save camera.extrinsics.yaml (ROS-style extrinsics format)
  // T is T_camera_lidar, we need T_lidar_camera for the YAML format
  // parent_frame: lidar, child_frame: camera means camera pose in lidar frame
  std::string extrinsics_file = output_path + "/camera.extrinsics.yaml";
  std::ofstream efile(extrinsics_file);
  if (efile.is_open()) {
    // Compute T_lidar_camera = inverse(T_camera_lidar)
    Eigen::Matrix4f T_lidar_camera = T.inverse();

    // Extract rotation matrix and convert to quaternion
    Eigen::Matrix3f R = T_lidar_camera.block<3, 3>(0, 0);
    Eigen::Quaternionf q(R);
    q.normalize();

    // Extract translation
    Eigen::Vector3f t = T_lidar_camera.block<3, 1>(0, 3);

    efile << "parent_frame: lidar\n";
    efile << "child_frame: camera\n";
    efile << "transform:\n";
    efile << "  translation:\n";
    efile << std::fixed << std::setprecision(11);
    efile << "    x: " << t.x() << "\n";
    efile << "    y: " << t.y() << "\n";
    efile << "    z: " << t.z() << "\n";
    efile << "  rotation_quaternion:\n";
    efile << "    x: " << q.x() << "\n";
    efile << "    y: " << q.y() << "\n";
    efile << "    z: " << q.z() << "\n";
    efile << "    w: " << q.w() << "\n";
    efile << "meta:\n";
    efile << "  rmse: " << result.rmse << "\n";
    efile.close();
    std::cout << "Extrinsics saved to: " << extrinsics_file << std::endl;
  }
}

// ============================================================================
// Main Calibration Logic
// ============================================================================

/**
 * @brief Process a single scene and return detected centers
 */
bool processScene(const SceneConfig& scene, const CalibConfig& config,
                  PointCloudXYZPtr& lidar_centers, PointCloudXYZPtr& qr_centers,
                  cv::Mat& annotated_image, PointCloudRingPtr& filtered_cloud) {
  std::cout << "\n--- Processing scene: " << scene.name << " ---" << std::endl;

  // Resolve paths
  std::string image_path = config.resolvePath(scene.image_path);
  std::string pcd_path = config.resolvePath(scene.pointcloud_path);

  // Load image
  cv::Mat image = cv::imread(image_path);
  if (image.empty()) {
    std::cerr << "Failed to load image: " << image_path << std::endl;
    return false;
  }
  std::cout << "Loaded image: " << image.cols << "x" << image.rows << std::endl;

  // Load point cloud
  PointCloudRingPtr raw_cloud(new PointCloudRing);
  if (!loadPointCloud(pcd_path, config.lidar_type, raw_cloud)) {
    return false;
  }
  std::cout << "Loaded point cloud: " << raw_cloud->size() << " points"
            << std::endl;

  // Apply filter
  filterPointCloud(raw_cloud, filtered_cloud, scene.filter);
  if (scene.filter.enabled) {
    std::cout << "After filter: " << filtered_cloud->size() << " points"
              << std::endl;
  }

  // Setup calibration parameters
  CalibParams params;
  params.camera = config.camera;
  params.target = config.target;

  // Setup ROI filter from scene config
  if (scene.filter.enabled) {
    params.lidar_filter.x_min = scene.filter.min[0];
    params.lidar_filter.x_max = scene.filter.max[0];
    params.lidar_filter.y_min = scene.filter.min[1];
    params.lidar_filter.y_max = scene.filter.max[1];
    params.lidar_filter.z_min = scene.filter.min[2];
    params.lidar_filter.z_max = scene.filter.max[2];
  }

  // Detect circles in LiDAR
  std::cout << "Detecting circles in LiDAR point cloud..." << std::endl;
  LiDARDetector lidar_detector(params);
  auto lidar_result = lidar_detector.detect(filtered_cloud, config.lidar_type);

  if (!lidar_result.success) {
    std::cerr << "LiDAR detection failed: " << lidar_result.error_message
              << std::endl;
    return false;
  }
  std::cout << "  Found " << lidar_result.centers->size() << " circle centers"
            << std::endl;

  // Debug: print lidar centers
  std::cout << "  LiDAR centers: ";
  for (size_t i = 0; i < lidar_result.centers->size(); ++i) {
    const auto& pt = lidar_result.centers->at(i);
    std::cout << "(" << pt.x << "," << pt.y << "," << pt.z << ") ";
  }
  std::cout << std::endl;

  // Detect ArUco markers
  std::cout << "Detecting ArUco markers in image..." << std::endl;
  QRDetector qr_detector(params);
  auto qr_result = qr_detector.detect(image);

  if (!qr_result.success) {
    std::cerr << "QR detection failed: " << qr_result.error_message
              << std::endl;
    return false;
  }
  std::cout << "  Found " << qr_result.centers->size() << " circle centers"
            << std::endl;

  // Debug: print QR centers
  std::cout << "  QR centers: ";
  for (size_t i = 0; i < qr_result.centers->size(); ++i) {
    const auto& pt = qr_result.centers->at(i);
    std::cout << "(" << pt.x << "," << pt.y << "," << pt.z << ") ";
  }
  std::cout << std::endl;

  // Store results
  lidar_centers = lidar_result.centers;
  qr_centers = qr_result.centers;
  annotated_image = qr_result.annotated_image;

  return true;
}

/**
 * @brief Run single-scene calibration
 */
CalibrationResult runSingleSceneCalibration(const CalibConfig& config) {
  const auto& scene = config.scenes[0];

  PointCloudXYZPtr lidar_centers, qr_centers;
  cv::Mat annotated_image;
  PointCloudRingPtr filtered_cloud(new PointCloudRing);

  if (!processScene(scene, config, lidar_centers, qr_centers, annotated_image,
                    filtered_cloud)) {
    CalibrationResult result;
    result.error_message = "Scene processing failed";
    return result;
  }

  // Compute calibration
  std::cout << "\nComputing extrinsic calibration..." << std::endl;
  CalibrationCalculator calculator;
  auto result = calculator.compute(lidar_centers, qr_centers);

  if (result.success) {
    std::cout << "\nCalibration successful!" << std::endl;
    std::cout << "RMSE: " << result.rmse << " m" << std::endl;

    // Save outputs
    std::string output_path = config.resolvePath(config.output.path);
    ensureOutputDir(output_path);

    // Save annotated image
    if (!annotated_image.empty()) {
      cv::imwrite(output_path + "/annotated_image.png", annotated_image);
    }

    // Create colored point cloud
    if (config.debug.save_colored_cloud) {
      std::cout << "Creating colored point cloud..." << std::endl;
      PointCloudXYZRGBPtr colored_cloud(new PointCloudXYZRGB);

      cv::Mat image = cv::imread(config.resolvePath(scene.image_path));
      cv::Mat camera_matrix =
          (cv::Mat_<double>(3, 3) << config.camera.fx, 0, config.camera.cx, 0,
           config.camera.fy, config.camera.cy, 0, 0, 1);
      cv::Mat dist_coeffs =
          (cv::Mat_<double>(5, 1) << config.camera.k1, config.camera.k2,
           config.camera.p1, config.camera.p2, 0);

      projectPointCloudToImage(filtered_cloud, result.transformation,
                               camera_matrix, dist_coeffs, image,
                               colored_cloud);

      if (!colored_cloud->empty()) {
        pcl::io::savePCDFileBinary(output_path + "/colored_cloud.pcd",
                                   *colored_cloud);
        std::cout << "Colored " << colored_cloud->size() << " points"
                  << std::endl;
      }
    }
  }

  return result;
}

/**
 * @brief Run multi-scene joint calibration
 */
CalibrationResult runMultiSceneCalibration(const CalibConfig& config) {
  std::vector<SceneData> scenes_data;
  std::vector<cv::Mat> annotated_images;
  std::vector<PointCloudRingPtr> filtered_clouds;

  // Process all scenes
  for (const auto& scene : config.scenes) {
    PointCloudXYZPtr lidar_centers, qr_centers;
    cv::Mat annotated_image;
    PointCloudRingPtr filtered_cloud(new PointCloudRing);

    if (!processScene(scene, config, lidar_centers, qr_centers, annotated_image,
                      filtered_cloud)) {
      std::cerr << "Failed to process scene: " << scene.name << std::endl;
      CalibrationResult result;
      result.error_message = "Scene processing failed: " + scene.name;
      return result;
    }

    scenes_data.emplace_back(lidar_centers, qr_centers);
    annotated_images.push_back(annotated_image);
    filtered_clouds.push_back(filtered_cloud);
  }

  // Perform multi-scene joint optimization
  std::cout << "\n=== Multi-Scene Joint Optimization ===" << std::endl;
  std::cout << "Total scenes: " << scenes_data.size() << std::endl;
  std::cout << "Total point correspondences: " << scenes_data.size() * 4
            << std::endl;

  CalibrationCalculator calculator;
  auto result = calculator.computeMultiScene(scenes_data);

  if (result.success) {
    std::cout << "\nMulti-scene calibration successful!" << std::endl;
    std::cout << "RMSE: " << result.rmse << " m" << std::endl;

    // Save outputs
    std::string output_path = config.resolvePath(config.output.path);
    ensureOutputDir(output_path);

    // Save annotated images for each scene
    for (size_t i = 0; i < annotated_images.size(); ++i) {
      if (!annotated_images[i].empty()) {
        std::string img_file =
            output_path + "/annotated_" + config.scenes[i].name + ".png";
        cv::imwrite(img_file, annotated_images[i]);
      }
    }

    // Create colored point clouds for each scene
    if (config.debug.save_colored_cloud) {
      std::cout << "Creating colored point clouds..." << std::endl;

      cv::Mat camera_matrix =
          (cv::Mat_<double>(3, 3) << config.camera.fx, 0, config.camera.cx, 0,
           config.camera.fy, config.camera.cy, 0, 0, 1);
      cv::Mat dist_coeffs =
          (cv::Mat_<double>(5, 1) << config.camera.k1, config.camera.k2,
           config.camera.p1, config.camera.p2, 0);

      for (size_t i = 0; i < config.scenes.size(); ++i) {
        cv::Mat image =
            cv::imread(config.resolvePath(config.scenes[i].image_path));
        if (image.empty()) continue;

        PointCloudXYZRGBPtr colored_cloud(new PointCloudXYZRGB);
        projectPointCloudToImage(filtered_clouds[i], result.transformation,
                                 camera_matrix, dist_coeffs, image,
                                 colored_cloud);

        if (!colored_cloud->empty()) {
          std::string pcd_file =
              output_path + "/colored_" + config.scenes[i].name + ".pcd";
          pcl::io::savePCDFileBinary(pcd_file, *colored_cloud);
          std::cout << "  " << config.scenes[i].name << ": "
                    << colored_cloud->size() << " points" << std::endl;
        }
      }
    }
  }

  return result;
}

// ============================================================================
// Main Entry Point
// ============================================================================

void printUsage(const char* progname) {
  std::cout << "FAST-Calib Core - Camera-LiDAR Calibration Tool\n" << std::endl;
  std::cout << "Usage: " << progname << " <config.yaml>\n" << std::endl;
  std::cout << "Arguments:" << std::endl;
  std::cout << "  config.yaml    Path to calibration configuration file\n"
            << std::endl;
  std::cout << "The configuration file specifies:" << std::endl;
  std::cout << "  - Camera intrinsics" << std::endl;
  std::cout << "  - LiDAR type (solid/mechanical)" << std::endl;
  std::cout << "  - Calibration target parameters" << std::endl;
  std::cout << "  - Scene(s) with image and point cloud paths" << std::endl;
  std::cout << "  - Output directory" << std::endl;
  std::cout << "\nFor single-scene calibration, define one scene." << std::endl;
  std::cout << "For multi-scene joint optimization, define multiple scenes."
            << std::endl;
}

int main(int argc, char** argv) {
  std::cout << "FAST-Calib Core Library v" << getVersionString() << std::endl;
  std::cout << "==========================================" << std::endl;

  if (argc < 2) {
    printUsage(argv[0]);
    return 1;
  }

  std::string config_file = argv[1];

  // Parse configuration
  CalibConfig config;
  if (!ConfigParser::parse(config_file, config)) {
    std::cerr << "Failed to parse configuration file: " << config_file
              << std::endl;
    return 1;
  }

  ConfigParser::printConfig(config);

  // Run calibration
  CalibrationResult result;
  if (config.isMultiScene()) {
    result = runMultiSceneCalibration(config);
  } else {
    result = runSingleSceneCalibration(config);
  }

  if (!result.success) {
    std::cerr << "\nCalibration failed: " << result.error_message << std::endl;
    return 1;
  }

  // Print transformation
  std::cout << "\nTransformation matrix (T_camera_lidar):" << std::endl;
  std::cout << std::fixed << std::setprecision(6);
  for (int i = 0; i < 4; ++i) {
    std::cout << "  [";
    for (int j = 0; j < 4; ++j) {
      std::cout << std::setw(12) << result.transformation(i, j);
      if (j < 3) std::cout << ", ";
    }
    std::cout << "]" << std::endl;
  }

  // Save results
  std::string output_path = config.resolvePath(config.output.path);
  saveResult(output_path, config, result);

  std::cout << "\nDone!" << std::endl;
  return 0;
}
